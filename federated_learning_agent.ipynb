{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madch3m/Federated-learning-ml-graph/blob/main/federated_learning_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrlLpvbJRNBW"
      },
      "source": [
        "Hyperparams for the federated graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ycOAkUcSQCe8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "@dataclass\n",
        "class HParams:\n",
        "  num_clients: int = 10\n",
        "  smple_clients: float = 0.5\n",
        "  local_epochs: int = 2\n",
        "  local_batch_size: int = 64\n",
        "  rounds: int = 10\n",
        "  lr: float = 0.01\n",
        "  momentum: float = 0.0\n",
        "  seed: int = 42\n",
        "  iid: bool = True\n",
        "  device: str = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cxEZwc0SN7L"
      },
      "source": [
        "Convolutional Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PacE7ULvSR6H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from typing import List, Tuple\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.Conv2d(32,64,3,padding=1), nn.ReLU(),nn.MaxPool2d(2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64 * 7 * 7, 128), nn.ReLU(),\n",
        "        nn.Linear(128,10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5inAG1-TZNe"
      },
      "source": [
        "Data loading and splitting for clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hEqyfXP_TdvV"
      },
      "outputs": [],
      "source": [
        "hp = HParams()\n",
        "random.seed(hp.seed)\n",
        "torch.manual_seed(hp.seed)\n",
        "def load_data() -> Tuple[List[Subset], torch.utils.data.Dataset]:\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    if hp.iid:\n",
        "        sizes = [len(train) // hp.num_clients] * hp.num_clients\n",
        "\n",
        "        sizes[-1] += len(train) - sum(sizes)\n",
        "        shards = random_split(train, sizes, generator=torch.Generator().manual_seed(hp.seed))\n",
        "        clients = [Subset(train, s.indices) for s in shards]\n",
        "        return clients, test\n",
        "\n",
        "    else:\n",
        "        targets = torch.tensor(train.targets)\n",
        "        sorted_idx = targets.sort()[1].tolist()\n",
        "        sorted_ds = Subset(train, sorted_idx)\n",
        "        sizes = [len(sorted_ds) // hp.num_clients] * hp.num_clients\n",
        "        sizes[-1] += len(sorted_ds) - sum(sizes)\n",
        "        shards = []\n",
        "        start = 0\n",
        "        for size in sizes:\n",
        "            idxs = list(range(start, start + size))\n",
        "            shards.append(Subset(sorted_ds, idxs))\n",
        "            start += size\n",
        "        return shards, test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyDzpLkcWp4W"
      },
      "source": [
        "Client Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xjkXtryHT8vz"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "def client_update(global_model: nn.Module, dataset: Subset) -> Tuple[Dict[str, torch.Tensor], int]:\n",
        "    model = deepcopy(global_model).to(hp.device)\n",
        "    model.train()\n",
        "    loader = DataLoader(dataset, batch_size=hp.local_batch_size, shuffle=True, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=hp.lr, momentum=hp.momentum)\n",
        "\n",
        "    for epoch in range(hp.local_epochs):\n",
        "        for x, y in tqdm(loader, desc=f\"Local epoch {epoch+1}/{hp.local_epochs}\", leave=False):\n",
        "            x, y = x.to(hp.device), y.to(hp.device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return deepcopy(model.state_dict()), len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGWmIYIYR3b"
      },
      "source": [
        "Aggregation Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VkD8zQ0tee2t"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def fedavg(global_model: nn.Module, client_states: List[Tuple[Dict[str,torch.Tensor],int]]):\n",
        "    total_samples = sum(n for _, n in client_states)\n",
        "\n",
        "    avg_state = {k: torch.zeros_like(v, device=hp.device) for k, v in global_model.state_dict().items()}\n",
        "\n",
        "    for state_dict, n in client_states:\n",
        "        weight = n / total_samples\n",
        "        for k in avg_state.keys():\n",
        "          avg_state[k] += state_dict[k].to(hp.device) * weight\n",
        "    global_model.load_state_dict(avg_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C6sErAVtYTrM"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, testset) -> Tuple[float,float]:\n",
        "    model.eval().to(hp.device)\n",
        "    loader = DataLoader(testset, batch_size=512, shuffle=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct, total, total_loss = 0, 0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(hp.device), y.to(hp.device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return correct / total, total_loss / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKQ9XmpwZcMd"
      },
      "source": [
        "Orchestrator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UiructFRZdwc"
      },
      "outputs": [],
      "source": [
        "def orchestrate():\n",
        "    clients, testset = load_data()\n",
        "    global_model = CNN().to(hp.device)\n",
        "    history = {\"round\": [], \"acc\": [], \"loss\": []}\n",
        "\n",
        "    print(f\"Simulated FedAvg with {hp.num_clients} clients, {hp.rounds} rounds, \"f\"{hp.local_epochs} local epochs (iid = {hp.iid})\")\n",
        "\n",
        "    for rnd in range(1, hp.rounds + 1):\n",
        "        m = max(1, int(hp.smple_clients * hp.num_clients))\n",
        "        selected = random.sample(range(hp.num_clients), m)\n",
        "\n",
        "        client_states = []\n",
        "        for cid in selected:\n",
        "            state, n_samples = client_update(global_model, clients[cid])\n",
        "            client_states.append((state, n_samples))\n",
        "\n",
        "        fedavg(global_model, client_states)\n",
        "\n",
        "        acc, loss = evaluate(global_model, testset)\n",
        "        history[\"round\"].append(rnd)\n",
        "        history[\"acc\"].append(acc)\n",
        "        history[\"loss\"].append(loss)\n",
        "\n",
        "        tqdm.write(f\"[Round {rnd:02d}] Test Acc: {acc*100:5.2f}% | Test Loss: {loss:.4f}\")\n",
        "\n",
        "\n",
        "    torch.save(global_model.state_dict(), \"mnist_cnn.pt\")\n",
        "    print(\"Model saved\")\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Visualization of Testing and Accuracy Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history[\"round\"], history[\"acc\"], marker='o')\n",
        "plt.title(\"Federated Learning - Test Accuracy\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history[\"round\"],history[\"loss\"],marker='o', color='red')\n",
        "plt.title(\"Federated Learning - Test Loss\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxP3Z6emRHFU",
        "outputId": "943d8c17-9ad4-4ddf-91ef-2d9e59c34466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "orchestrate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOGKViUKOCp3HpFYQt676So",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
