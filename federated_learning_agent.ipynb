{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0ogcdZu674bQP6jmRJC2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madch3m/Federated-learning-ml-graph/blob/main/federated_learning_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv6hav8YTmSU",
        "outputId": "02fc3a8a-efa2-48c1-9673-180f1761aa34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-utils\n",
            "  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torch-utils) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-utils) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torch-utils) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torch-utils) (3.0.3)\n",
            "Building wheels for collected packages: torch-utils\n",
            "  Building wheel for torch-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6188 sha256=a74adcf30899025df19058039b05e29d5f74c9e26dff1831eb3ddc5af5b7b195\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/06/32/1d26da91e30177d171ecb60995273ad8709ca2b6ce66ccefa7\n",
            "Successfully built torch-utils\n",
            "Installing collected packages: torch-utils\n",
            "Successfully installed torch-utils-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparams for the federated graph"
      ],
      "metadata": {
        "id": "SrlLpvbJRNBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ycOAkUcSQCe8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "@dataclass\n",
        "class HParams:\n",
        "  num_clients: int = 10\n",
        "  smple_clients: float = 0.5\n",
        "  local_epochs: int = 2\n",
        "  local_batch_size: int = 64\n",
        "  rounds: int = 10\n",
        "  lr: float = 0.01\n",
        "  momentum: float = 0.0\n",
        "  seed: int = 42\n",
        "  iid: bool = True\n",
        "  device: str = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Net"
      ],
      "metadata": {
        "id": "8cxEZwc0SN7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from typing import List, Tuple\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(1,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.Conv2d(32,64,3,padding=1), nn.ReLU(),nn.MaxPool2d(2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64 * 7 * 7, 128), nn.ReLU(),\n",
        "        nn.Linear(128,10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "PacE7ULvSR6H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading and splitting for clients"
      ],
      "metadata": {
        "id": "o5inAG1-TZNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp = HParams()\n",
        "random.seed(hp.seed)\n",
        "torch.manual_seed(hp.seed)\n",
        "def load_data() -> Tuple[List[Subset], torch.utils.data.Dataset]:\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    if hp.iid:\n",
        "        sizes = [len(train) // hp.num_clients] * hp.num_clients\n",
        "\n",
        "        sizes[-1] += len(train) - sum(sizes)\n",
        "        shards = random_split(train, sizes, generator=torch.Generator().manual_seed(hp.seed))\n",
        "        clients = [Subset(train, s.indices) for s in shards]\n",
        "        return clients, test\n",
        "\n",
        "    else:\n",
        "        targets = torch.tensor(train.targets)\n",
        "        sorted_idx = targets.sort()[1].tolist()\n",
        "        sorted_ds = Subset(train, sorted_idx)\n",
        "        sizes = [len(sorted_ds) // hp.num_clients] * hp.num_clients\n",
        "        sizes[-1] += len(sorted_ds) - sum(sizes)\n",
        "        shards = []\n",
        "        start = 0\n",
        "        for size in sizes:\n",
        "            idxs = list(range(start, start + size))\n",
        "            shards.append(Subset(sorted_ds, idxs))\n",
        "            start += size\n",
        "        return shards, test\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "hEqyfXP_TdvV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Client Logic"
      ],
      "metadata": {
        "id": "XyDzpLkcWp4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def client_update(global_model: nn.Module, dataset: Subset) -> Tuple[Dict[str, torch.Tensor], int]:\n",
        "    model = deepcopy(global_model).to(hp.device)\n",
        "    model.train()\n",
        "    loader = DataLoader(dataset, batch_size=hp.local_batch_size, shuffle=True, drop_last=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=hp.lr, momentum=hp.momentum)\n",
        "\n",
        "    for _ in range(hp.local_epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(hp.device), y.to(hp.device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return deepcopy(model.state_dict(), len(dataset))"
      ],
      "metadata": {
        "id": "xjkXtryHT8vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation Logic"
      ],
      "metadata": {
        "id": "seGWmIYIYR3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def fedavg(global_model: nn.Module, client_states: List[Tuple[Dict[str,torch.Tensor],int]]):\n",
        "    total_samples = sum(n for _, n in client_states)\n",
        "\n",
        "    avg_state = {k: torch.zeros_like(v, device=hp.device) for k, v in global_model.state_dict().items()}\n",
        "\n",
        "    for state_dict, n in client_states:\n",
        "        weight = n / total_samples\n",
        "        for k in avg_state.keys():\n",
        "          avg_state[k] += state_dict[k].to(hp.device) * weight\n",
        "    global_model.load_state_dict(avg_state)"
      ],
      "metadata": {
        "id": "VkD8zQ0tee2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model: nn.Module, testset) -> Tuple[float,float]:\n",
        "    model.eval().to(hp.device)\n",
        "    loader = DataLoader(testset, batch_size=512, shuffle=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct, total, total_loss = 0, 0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(hp.device), y.to(hp.device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return correct / total, total_loss / total\n"
      ],
      "metadata": {
        "id": "C6sErAVtYTrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orchestrator"
      ],
      "metadata": {
        "id": "dKQ9XmpwZcMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def orchestrate():\n",
        "    clients, testset = load_data()\n",
        "    global_model = CNN().to(hp.device)\n",
        "\n",
        "    for rnd in range(1, hp.rounds + 1):\n",
        "        m = max(1, int(hp.frac_clients * hp.num_clients))\n",
        "        selected = random.sample(range(hp.num_clients), m)\n",
        "\n",
        "        client_states = []\n",
        "        for cid in selected:\n",
        "            state, n_samples = client_update(global_model, clients[cid])\n",
        "            client_states.append((state, n_samples))\n",
        "\n",
        "        fedavg(global_model, client_states)\n",
        "\n",
        "        acc, los = evaluate(global_model, testset)\n",
        "\n",
        "\n",
        "    torch.save(global_model.state_dict(), \"mnist_cnn.pt\")\n",
        "    print(\"Model saved\")\n"
      ],
      "metadata": {
        "id": "UiructFRZdwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}